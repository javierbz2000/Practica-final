{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/javierbz2000/Practica-final/blob/main/Practica_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PRACTICA FINAL**"
      ],
      "metadata": {
        "id": "IPOqIPl-1FM4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizada por: \n",
        "- Javier Bañares\n",
        "- Manuel Ramirez\n",
        "- Javier Amezaga\n",
        "- Claudia Corbella"
      ],
      "metadata": {
        "id": "tzV1YHrg1JVC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdH70-qvor6W"
      },
      "source": [
        "# Importacion de librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEYynA8zX2od"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from pandas.core.algorithms import mode\n",
        "from sklearn.inspection import permutation_importance\n",
        "import multiprocessing\n",
        "from time import sleep\n",
        "from random import shuffle\n",
        "from numpy import atleast_2d\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.neighbors import KDTree\n",
        "#from hdbscan import HDBSCAN\n",
        "from matplotlib.colors import ListedColormap\n",
        "from matplotlib import cm\n",
        "import matplotlib.ticker as ticker\n",
        "import plotly.io as plot_io\n",
        "import plotly.graph_objects as go\n",
        "from numpy.random import rand, seed\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from sklearn.datasets import make_blobs, make_circles, make_moons,load_iris\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.cluster import KMeans, SpectralClustering, DBSCAN, AgglomerativeClustering\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.manifold import TSNE, Isomap\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "from sklearn.impute import KNNImputer\n",
        "import scipy.stats as ss\n",
        "import warnings\n",
        "import sklearn\n",
        "from sklearn.pipeline import Pipeline\n",
        "!pip install category_encoders\n",
        "import category_encoders as ce\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, GradientBoostingRegressor\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, \\\n",
        "                            silhouette_score, recall_score, precision_score, make_scorer, \\\n",
        "                            roc_auc_score, f1_score, precision_recall_curve, accuracy_score, roc_auc_score, \\\n",
        "                            classification_report, confusion_matrix, plot_confusion_matrix, adjusted_mutual_info_score, \\\n",
        "                            mean_squared_error\n",
        "\n",
        "from sklearn.model_selection import cross_val_score,train_test_split, RepeatedKFold, KFold, GridSearchCV, ParameterGrid\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBh5GLgKozsh"
      },
      "source": [
        "# Importacion de la base de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kT4PpxmVXdc9"
      },
      "outputs": [],
      "source": [
        "Datos = pd.read_csv(\"NCDB_1999_to_2014.csv\")\n",
        "Datos.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VedzTo2mo70W"
      },
      "source": [
        "# Analisis exploratorio inicial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80wETL6ko8YK"
      },
      "outputs": [],
      "source": [
        "Datos.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFyoMlAdy9dI"
      },
      "source": [
        "Un primer analisis exploratorio muestra que el dataset tiene inicialmente un total de 5860405 filas y 22 columnas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_KdvG7LpY9X"
      },
      "source": [
        "## Tipos de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_UtmabIfjhX"
      },
      "outputs": [],
      "source": [
        "Datos.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqrsG8D-Fwqb"
      },
      "source": [
        "Podemos observar que la mayoria de las variables son tipo object a pesar de que la mayoria contienen datos numericos. Estos es porque en muchas hay valores no numericos cuyo significado equivalen a valores NA y estos son valores UU (Unknown), QQ o NN.\n",
        "\n",
        "Mas adelante realizaremos un analisis sobre estos valores, y segun los resultados, decidiremos como tratarlos. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfnKXD9BUdMM"
      },
      "outputs": [],
      "source": [
        "Datos.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-7PIImXUqFH"
      },
      "outputs": [],
      "source": [
        "Datos.select_dtypes(include='object').nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n5qvHJFHN5Z"
      },
      "source": [
        "Con la función unique podemos observar los diferentes valores/opciones que podemos encontrar dentro de cada variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQz1t5OcUvTz"
      },
      "outputs": [],
      "source": [
        "Datos.select_dtypes(include='int64').nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlUI84hmHbOy"
      },
      "source": [
        "Observamos que la severidad del accidente cuenta con dos valores, 1 si la colisión cuenta con una fatalidad y 2 si la colisión no hay ninguna fatalidad, por lo que la usaremos como variable de referencia a la hora de tratar la acción correctiva de la prima y el descuento de la prima"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIlU1O9nU0tg"
      },
      "outputs": [],
      "source": [
        "#corr_datos = Datos.corr(method='pearson')\n",
        "\n",
        "#plt.figure(figsize=(8, 6))\n",
        "#sns.heatmap(corr_datos, annot=True)\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdvTtyOlUNG0"
      },
      "source": [
        "# Tratamiento de valores faltantes (MISSING, UNKNOWN...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqbkrzC68orf"
      },
      "source": [
        "Comenzamos realizando un analisis de los valores missing sabiendo cuantos hay en cada una de las variables "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o302-g86UMfX"
      },
      "outputs": [],
      "source": [
        "missing_values_count = Datos.isna().sum()\n",
        "missing_values_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyaGSSn_9HOM"
      },
      "source": [
        "El numero de missings es muy bajo por lo que decidimos eliminarlos, ya que no va a suponer una distorsion de los datos "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAp6WVWSUb5J"
      },
      "outputs": [],
      "source": [
        "Datos=Datos.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1Ybm7MNEih_"
      },
      "source": [
        "A través de los siguientes codigos hemos comenzado analizando la cantidad de valores de tipo U, N, X y Q que hay por filas, y segun los resultados decimos que hacer PARA su tratamiento "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djOr3R1S6o9x"
      },
      "outputs": [],
      "source": [
        "pd_series_U_filas = Datos.isin([\"U\", \"UU\", \"UUUU\"]).sum(axis=1).sort_values(ascending=False)\n",
        "total_U_f= pd.DataFrame(pd_series_U_filas, columns=['U_filas'])   \n",
        "total_U_f['porcentaje_filas_U'] = (total_U_f['U_filas']/Datos.shape[1])*100\n",
        "total_U_f\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2zczzNEX75J"
      },
      "outputs": [],
      "source": [
        "pd_series_N_filas = Datos.isin([\"N\",\"NN\",\"NNNN\"]).sum(axis=1).sort_values(ascending=False)\n",
        "total_N_f= pd.DataFrame(pd_series_N_filas, columns=['N_filas'])   \n",
        "total_N_f['porcentaje_filas_N'] = (total_N_f['N_filas']/Datos.shape[1])*100\n",
        "total_N_f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rd69LLr6Zxul"
      },
      "outputs": [],
      "source": [
        "pd_series_Q_filas = Datos.isin([\"Q\", \"QQ\", \"QQQQ\"]).sum(axis=1).sort_values(ascending=False)\n",
        "total_Q_f= pd.DataFrame(pd_series_Q_filas, columns=['Q_filas'])   \n",
        "total_Q_f['porcentaje_filas_Q'] = (total_Q_f['Q_filas']/Datos.shape[1])*100\n",
        "total_Q_f"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUm7DiJC_9gR"
      },
      "source": [
        "Una de las opciones que tenemos es eliminar todos los valores, pero al haber una gran cantidad disttorsionaria los datos. Por lo tanto hemos decidido eliminar todas las filas que contengan mas de un 30% de cada tipo de estos valores. Esto lo hemos hecho utilizando el threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nWk_RwMNG2N"
      },
      "outputs": [],
      "source": [
        "threshold=30\n",
        "list_vars_not_U=total_U_f[total_U_f['porcentaje_filas_U']>threshold]\n",
        "Columnas_drop_u= list(list_vars_not_U.index)\n",
        "Datos= Datos.drop(Columnas_drop_u)\n",
        "Datos.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkgtTLhXYaSd"
      },
      "outputs": [],
      "source": [
        "threshold=30\n",
        "list_vars_not_N=total_U_f[total_N_f['porcentaje_filas_N']>threshold]\n",
        "Columnas_drop_N= list(list_vars_not_N.index)\n",
        "Datos= Datos.drop(Columnas_drop_N)\n",
        "Datos.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZnQ70pDaFBL"
      },
      "outputs": [],
      "source": [
        "threshold=30\n",
        "list_vars_not_Q=total_Q_f[total_Q_f['porcentaje_filas_Q']>threshold]\n",
        "Columnas_drop_Q= list(list_vars_not_Q.index)\n",
        "Datos= Datos.drop(Columnas_drop_Q)\n",
        "Datos.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMMYt4cBAsK3"
      },
      "source": [
        "Una vez hecho esto, hemos analizado el porcentaje de cada uno de los valores U, N y Q que tiene cada variable por columna. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9qjgCrAZjXs"
      },
      "outputs": [],
      "source": [
        "pd_series_U_columns = Datos.isin([\"U\", \"UU\", \"UUUU\"]).sum().sort_values(ascending=False)\n",
        "total_U_c= pd.DataFrame(pd_series_U_columns, columns=['U_columnas'])   \n",
        "total_U_c['porcentaje_columnas'] = (total_U_c['U_columnas']/Datos.shape[0])*100\n",
        "total_U_c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9B7B5Er1ZPpK"
      },
      "outputs": [],
      "source": [
        "pd_series_N_columns = Datos.isin([\"N\",\"NN\",\"NNNN\"]).sum().sort_values(ascending=False)\n",
        "total_N_c= pd.DataFrame(pd_series_N_columns, columns=['N_columnas'])   \n",
        "total_N_c['porcentaje_columnas_N'] = (total_N_c['N_columnas']/Datos.shape[0])*100\n",
        "total_N_c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1nhDh8XaRGn"
      },
      "outputs": [],
      "source": [
        "pd_series_Q_columns = Datos.isin([\"Q\", \"QQ\", \"QQQQ\"]).sum().sort_values(ascending=False)\n",
        "total_Q_c= pd.DataFrame(pd_series_Q_columns, columns=['Q_columnas'])   \n",
        "total_Q_c['porcentaje_columnas_Q'] = (total_Q_c['Q_columnas']/Datos.shape[0])*100\n",
        "total_Q_c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5QF4DOfBhZO"
      },
      "source": [
        "Vemos que el porcentaje en los tres tipos esta por debajo del 30%, pero aun sigue habiendo. El % de valores N y Q es bastante bajo por lo que vamos a eliminar dichas filas. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASlnntRdTGJl"
      },
      "source": [
        "## ELIMINACION DE TODOS LOS VALORES \"N\" Y \"Q\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2RKwYZqavxt"
      },
      "outputs": [],
      "source": [
        "Datos = Datos.drop(Datos[Datos['P_SAFE']==\"NN\"].index)\n",
        "Datos = Datos.drop(Datos[Datos['P_ISEV']==\"N\"].index)\n",
        "Datos = Datos.drop(Datos[Datos['V_YEAR']==\"NNNN\"].index)\n",
        "Datos = Datos.drop(Datos[Datos['V_TYPE']==\"NN\"].index)\n",
        "Datos = Datos.drop(Datos[Datos['P_AGE']==\"NN\"].index)\n",
        "Datos = Datos.drop(Datos[Datos['P_SEX']==\"N\"].index)\n",
        "Datos = Datos.drop(Datos[Datos['P_PSN']==\"NN\"].index)\n",
        "Datos = Datos.drop(Datos[Datos['C_CONF']==\"QQ\"].index)\n",
        "Datos = Datos.drop(Datos[Datos['C_RSUR']==\"Q\"].index)\n",
        "Datos = Datos.drop(Datos[Datos['C_RCFG']==\"QQ\"].index)\n",
        "Datos = Datos.drop(Datos[Datos['C_TRAF']==\"QQ\"].index)\n",
        "Datos = Datos.drop(Datos[Datos['C_RALN']==\"Q\"].index)\n",
        "Datos = Datos.drop(Datos[Datos['P_PSN']==\"QQ\"].index)\n",
        "Datos = Datos.drop(Datos[Datos['C_WTHR']==\"Q\"].index)\n",
        "Datos = Datos.drop(Datos[Datos['P_SAFE']==\"QQ\"].index)\n",
        "Datos = Datos.drop(Datos[Datos['V_TYPE']==\"QQ\"].index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lI-MmRwyU7_4"
      },
      "source": [
        "## SUSTITUCION DE TODOS LOS VALORES UNKNOWN POR LA MODA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbcZzMyEB5tQ"
      },
      "source": [
        "Sin embargo, como se observa anteriormente, la cantidad de U sigue siendo alta en la mayoria de los datos por lo que hemos optado por sustituir estos valores por la moda de cada columna."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6awngzR_MLYZ"
      },
      "outputs": [],
      "source": [
        "UU_columns=Datos.isin([\"U\", \"UU\", \"UUUU\"]).columns.tolist()\n",
        "def mode_columns (df):\n",
        "  for column in df:\n",
        "    if(column in UU_columns):\n",
        "      df[column]=df[column].replace(\"U\", df[column].mode()[0])\n",
        "      df[column]=df[column].replace(\"UU\", df[column].mode()[0])\n",
        "      df[column]=df[column].replace(\"UUUU\", df[column].mode()[0])\n",
        "   \n",
        "\n",
        "  return mode_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wtz89A2INFUU"
      },
      "outputs": [],
      "source": [
        "mode_columns(Datos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IncVrMDTT57"
      },
      "source": [
        "La variable P_AGE no se ve afectada y sigue con datos desconocidos, por lo que puede deberse a que la moda sean esos datos desconocidos, por tanto se procederá a tratar así."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0btfJIsWFcj"
      },
      "outputs": [],
      "source": [
        "Datos = Datos.drop(Datos[Datos['P_AGE']==\"UU\"].index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWVhW7C7CRlP"
      },
      "source": [
        "Tras estas modificaciones la tabla resultante pasa a tener XXX filas y mantienen las mismas columnas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOGp1pZaV-4J"
      },
      "outputs": [],
      "source": [
        "Datos.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6yBUNIkCifN"
      },
      "source": [
        "Estas modificaciones nos permiten tratar las variables confundidas y convertirlas en tipo int (numerico)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LohOvjh6ekyx"
      },
      "outputs": [],
      "source": [
        "Datos.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mru5ZC0-Y4-F"
      },
      "outputs": [],
      "source": [
        "Datos['C_MNTH'] = Datos['C_MNTH'].astype(int)\n",
        "Datos['C_WDAY'] = Datos['C_WDAY'].astype(int)\n",
        "Datos['C_HOUR'] = Datos['C_HOUR'].astype(int)\n",
        "Datos['C_VEHS'] = Datos['C_VEHS'].astype(int)\n",
        "Datos['C_CONF'] = Datos['C_CONF'].astype(int)\n",
        "Datos['C_WTHR'] = Datos['C_WTHR'].astype(int)\n",
        "Datos['C_RSUR'] = Datos['C_RSUR'].astype(int)\n",
        "Datos['C_RALN'] = Datos['C_RALN'].astype(int)\n",
        "Datos['C_TRAF'] = Datos['C_TRAF'].astype(int)\n",
        "Datos['C_RCFG'] = Datos['C_RCFG'].astype(int)\n",
        "Datos['V_ID'] = Datos['V_ID'].astype(int)\n",
        "Datos['V_TYPE'] = Datos['V_TYPE'].astype(int)\n",
        "Datos['V_YEAR'] = Datos['V_YEAR'].astype(int)\n",
        "Datos['P_ID'] = Datos['P_ID'].astype(int)\n",
        "Datos['P_PSN'] = Datos['P_PSN'].astype(int)\n",
        "Datos['P_ISEV'] = Datos['P_ISEV'].astype(int)\n",
        "Datos['P_USER'] = Datos['P_USER'].astype(int)\n",
        "Datos['P_SAFE'] = Datos['P_SAFE'].astype(int)\n",
        "Datos['P_AGE'] = Datos['P_AGE'].astype(int)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReKPOFKBCuU1"
      },
      "source": [
        "Tras estas modificaciones, la unica variable tipo object que queda es la variable P_SEX que procederemos mas adelante a convertirla en una variable tipo dummy para poder hacer el analisis y tener toda la tabla con datos tipo numerico."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Separacion del modelo en train y test"
      ],
      "metadata": {
        "id": "NXFm3b4-Hah9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_Datos_train, X_Datos_test, y_Datos_train, y_Datos_test = train_test_split(Datos.drop(\"C_SEV\",axis=1), \n",
        "                                                                     Datos[\"C_SEV\"], \n",
        "                                                                     stratify= Datos[\"C_SEV\"], \n",
        "                                                                     test_size=0.2)\n",
        "Datos_train = pd.concat([X_Datos_train, y_Datos_train],axis=1)\n",
        "Datos_test = pd.concat([X_Datos_test, y_Datos_test],axis=1)"
      ],
      "metadata": {
        "id": "1Y5qdz7iHZI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con la funcion train_test_split separamos las tabla en un grupo train y otro test. Para dicha separacion hemos tenido en cuenta el balanceo de datos de la variable principal\n",
        "\n",
        "Los datos del grupo train estan en la variable \"Datos_train\" y los datos del grupo test en la variable \"Datos_test\". "
      ],
      "metadata": {
        "id": "2zZFIuxCH1cW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transforacion variables categoricas"
      ],
      "metadata": {
        "id": "nnG7jorTH5Js"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez divido el data set en train y test, transformamos en el Data set de datos train que esta en la variable \"Datos_train\", la unica variable tipo object que nos queda \"P_SEX\" utilizando la fundion OneHotEncoder. Incluimos el dataset resultante en la variable Datos_train_dummy\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5_WX-i-8H5fv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Datos_train=Datos_train.set_index([\"C_SEV\"])\n",
        "list_columns_cat = list(Datos_train.select_dtypes(\"object\").columns)\n",
        "list_other = list(set(Datos_train.columns)-set(list_columns_cat))"
      ],
      "metadata": {
        "id": "0ecf9TV3H_nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ohe = ce.OneHotEncoder(cols=list_columns_cat)\n",
        "model = ohe.fit(Datos_train)"
      ],
      "metadata": {
        "id": "uzQFV3O4H__-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Datos_train_dummy = model.transform(Datos_train)\n",
        "Datos_train_dummy.dtypes.to_dict()"
      ],
      "metadata": {
        "id": "UPk3-snJHyu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Relizamos el mismo proceso de conversion de la variable P_SEX para el dataset test que esta en la variable Datos_test. Incluimos el dataset resultante en la varible Datos_test_dummy\n"
      ],
      "metadata": {
        "id": "XLfF4ECkIGTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_columns_cat_test = list(Datos_test.select_dtypes(\"object\").columns)\n",
        "list_other_test = list(set(Datos_test.columns)-set(list_columns_cat_test))"
      ],
      "metadata": {
        "id": "pHJXmFJYIMKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ohe = ce.OneHotEncoder(cols=list_columns_cat_test)\n",
        "model = ohe.fit(Datos_test)"
      ],
      "metadata": {
        "id": "EMYdOgt2INnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Datos_test_dummy = model.transform(Datos_test)\n",
        "Datos_test_dummy.dtypes.to_dict()"
      ],
      "metadata": {
        "id": "IXqIO7NQIPDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ¿Qué tipos de vehículos (modelos, antigüedad, etc.) y conductores son más propensos a tener accidentes (acción correctiva en prima)?"
      ],
      "metadata": {
        "id": "2jc3d7B4IPyr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para analizar cuales son las caracteristicas de los vehiculos y las caracteristicas de los conductores que tienen una mayor propension a tener mas accidentes, hemos considerado que vamos relizar un analisis utilizando la funcion groupby()\n",
        "Comenzamos creando una nueva variable en la que solo se encuentran las variables que nos pueden proporcionar estas caracteristicas, a partir del data set que se encuentra en Datos_test_dummy y Datos_train_dummy . Estas variables son: V_YEAR, V_TYPE,P_AGE, P_SEX_1, P_SEX_2, P_USER, P_SAFE, P_PSN y P_ISEV\n",
        "\n",
        "Por lo tanto vamos a utilizar unicamente las variables X_Datos_train_acc y X_Datos_test_acc que contienen unicamente las variables mencionadas anteriormente a partir de los datos train y test que tiene las variables tipo object ya transformadas."
      ],
      "metadata": {
        "id": "FxOZZwJZIUP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_Datos_train_acc=Datos_train_dummy[[\"V_YEAR\",\"V_TYPE\",\"P_AGE\",\"P_SEX_1\",\"P_USER\",\"P_SAFE\", \"P_PSN\", \"P_ISEV\"]]\n",
        "X_Datos_test_acc=Datos_test_dummy[[\"V_YEAR\",\"V_TYPE\",\"P_AGE\",\"P_SEX_1\",\"P_USER\",\"P_SAFE\",\"P_PSN\", \"P_ISEV\",\"C_SEV\"]]\n",
        "X_Datos_train_acc.head()\t"
      ],
      "metadata": {
        "id": "uS5H-9j-IapC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La columna V_YEAR contiene los datos del año en el que el vehiculo fue producido. La fecha minima de esta columna es 1901 y la fecha maxima el 2015. Teniendo en cuenta que son 114 años entre años hemos optado por analizarlo de dos formas. Por una parte, agrupar los datos por las fechas que contiene la columna \"V_YEAR\" y por otra, para facilitar el analisis y obtener resultados mas generales, hemos creado una nueva columna que contiene los terciles de la columna V_YEAR y segun el año del vehiculo, obtendra una etiqueta u otra. Esta nueva columna es Year_range\n"
      ],
      "metadata": {
        "id": "O_peTRQIIWtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conditionlist = [\n",
        "    (X_Datos_train_acc[\"V_YEAR\"]>=1901) & (X_Datos_train_acc[\"V_YEAR\"]<=1939) ,\n",
        "    (X_Datos_train_acc[\"V_YEAR\"]>=1940) & (X_Datos_train_acc[\"V_YEAR\"]<=1978),\n",
        "    (X_Datos_train_acc[\"V_YEAR\"]>=1979) & (X_Datos_train_acc[\"V_YEAR\"]<=2015)]\n",
        "\n",
        "choicelist = ['1901-1939', '1940-1978',\"1979-2015\"]\n",
        "X_Datos_train_acc[\"Year_range\"] = np.select(conditionlist, choicelist,default='otro')\n",
        "X_Datos_train_acc"
      ],
      "metadata": {
        "id": "ZIrdAEbgIX1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como ocurre con la variable V_YEAR, la variable P_AGE contine la edad del conductor, al ser el numero maximo 99 y el minimo 1 hay muchos valores por lo que vamos a crear una nueva columna en la que dividimos dicha variable en tramos.Esta nueva columna se llama AGE_RANGE y contiene un total de 10 rangos el primero va de 1 a 18 y el segundo de 18 a 20, a apartir del tercero van de 10 en 10.\n"
      ],
      "metadata": {
        "id": "Cj6tmkRLIfTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conditionlistt = [\n",
        "    (X_Datos_train_acc[\"P_AGE\"]>=1) & (X_Datos_train_acc[\"P_AGE\"]<=18) ,\n",
        "    (X_Datos_train_acc[\"P_AGE\"]>=18) & (X_Datos_train_acc[\"P_AGE\"]<=20),\n",
        "    (X_Datos_train_acc[\"P_AGE\"]>=21) & (X_Datos_train_acc[\"P_AGE\"]<=30),\n",
        "    (X_Datos_train_acc[\"P_AGE\"]>=31) & (X_Datos_train_acc[\"P_AGE\"]<=40),\n",
        "    (X_Datos_train_acc[\"P_AGE\"]>=41) & (X_Datos_train_acc[\"P_AGE\"]<=50),\n",
        "    (X_Datos_train_acc[\"P_AGE\"]>=51) & (X_Datos_train_acc[\"P_AGE\"]<=60),\n",
        "    (X_Datos_train_acc[\"P_AGE\"]>=61) & (X_Datos_train_acc[\"P_AGE\"]<=70),\n",
        "    (X_Datos_train_acc[\"P_AGE\"]>=71) & (X_Datos_train_acc[\"P_AGE\"]<=80),\n",
        "    (X_Datos_train_acc[\"P_AGE\"]>=81) & (X_Datos_train_acc[\"P_AGE\"]<=90),\n",
        "    (X_Datos_train_acc[\"P_AGE\"]>=91) & (X_Datos_train_acc[\"P_AGE\"]<=99)]\n",
        "\n",
        "choicelistt = ['1-18', '18-20',\"20-30\",\"30-40\",\"40-50\",\"50-60\",\"60-70\",\"70-80\",\"80-90\",\"90-99\"]\n",
        "X_Datos_train_acc[\"AGE_RANGE\"] = np.select(conditionlistt, choicelistt)\n",
        "X_Datos_train_acc"
      ],
      "metadata": {
        "id": "JnDMLchYIfwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Una vez creada la nueva columna, procedemos a resetear el index el cual es la columna C_SEV "
      ],
      "metadata": {
        "id": "XQh5kII2In8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_Datos_train_acc=X_Datos_train_acc.reset_index()"
      ],
      "metadata": {
        "id": "K-NasuT5IoRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Asi mismo, como menciona el apartado, unicamente queremos saber las caracteristicas de los condcutores. Esta informacion la contiene la el valor 11 de la variable P_PSN o el valor 1 d ela variable P_USER. Podemos seleccionar el valor de una o de otra indiferentemente. Por lo que unicamente vamos a selecionar ese valor 11 de la variable P_PSN\n"
      ],
      "metadata": {
        "id": "bsHGP-q3Isyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_Datos_train_acc= X_Datos_train_acc[X_Datos_train_acc[\"P_PSN\"].isin([11])]"
      ],
      "metadata": {
        "id": "LQGeCt_lIvUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como hemos mencionando anteriormente, la variable C_SEV contiene dos valores:\n",
        "\n",
        "    1-> cuando la colision ha producido al menos una fatalidad\n",
        "    2-> cuando la colision no ha producido ninguna fatalidad\n",
        "\n",
        "En base a esto, como no hay ninguna columna que contenga los datos sobre la accion correctiva en prima o el descuenta en prima, hemos interpretado que para establecer una u otra va a depender de si hay al menos una fatalidad o de si no hay ninguna fatalidad.\n",
        "\n",
        "Para el caso de la accion correctiva en prima esta se aplicara su la colision cuenta con al menos 1 fatalidad. Esta informacion la contiene el valor \"1\" de la variable C_SEV y como es lo que queremos estudiar en ete apartado, procedemos a selecionar unicamente los valores \"1\" de esta columna. \n"
      ],
      "metadata": {
        "id": "zHTKXLSkI2lO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_Datos_train_acc1= X_Datos_train_acc[X_Datos_train_acc[\"C_SEV\"].isin([1])]"
      ],
      "metadata": {
        "id": "khLGqVfnI3iI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agrupamos la variable V_TYPE y sumamos cuantos datos C_SEV hay en cada valor de variable por la que agrupamos"
      ],
      "metadata": {
        "id": "pxfLiQvkI50k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "V_TYPE1 = X_Datos_train_acc1[[\"C_SEV\",\"V_TYPE\"]].groupby([\"V_TYPE\"]).count()\n",
        "V_TYPE1\n"
      ],
      "metadata": {
        "id": "cWzJOFHQI616"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax2 = plt.subplots(nrows = 1, figsize=(10,5))\n",
        "V_TYPE1.plot(ax = ax2, kind = 'bar')\n",
        "ax2.title.set_text('Colisiones con fatalidad por tipo de vehiculo')"
      ],
      "metadata": {
        "id": "I4hp5kfnI7Zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como comentabamos previamente. Para el analisis del año de produccion de cada vehiculo, primero agrupamos la variable V_YEAR y sumamos cuantos datos C_SEV hay en cada valor de la variable por la que agrupamos\n"
      ],
      "metadata": {
        "id": "jDvwaf6_JC8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "V_YEAR1= X_Datos_train_acc1[['C_SEV','V_YEAR']].groupby(['V_YEAR']).count()\n",
        "V_YEAR1\n"
      ],
      "metadata": {
        "id": "D04HP9lGJEwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax2 = plt.subplots(nrows = 1, figsize=(20,10))\n",
        "V_YEAR1.plot(ax = ax2, kind = 'bar')\n",
        "ax2.title.set_text('Colisiones con fatalidad por año del modelo de vehiculo')"
      ],
      "metadata": {
        "id": "rERONX0zJGsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En segundo lugar, para obtener unos resultados mas generales agrupamos la variable Year_range y sumamos cuantos datos C_SEV hay en cada valor por el que agrupamos \n"
      ],
      "metadata": {
        "id": "zocBO0nZJIou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "Year_range1= X_Datos_train_acc1[['C_SEV','Year_range']].groupby(['Year_range']).count()\n",
        "Year_range1\n"
      ],
      "metadata": {
        "id": "gi174eNMJKb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax2 = plt.subplots(nrows = 1, figsize=(15,8))\n",
        "Year_range1.plot(ax = ax2, kind = 'bar')\n",
        "ax2.title.set_text('Colisiones con fatalidad por intervalo de año del modelo de vehiculo')"
      ],
      "metadata": {
        "id": "UtUwN8H2JNmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hemos dedicido que para el analisis de la edad unicamente vamos a realizar la agrupacion sobre la variable \"AGE_RANGE\""
      ],
      "metadata": {
        "id": "U8sPn7YGJP_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "AGE_RANGE1=X_Datos_train_acc1[['C_SEV','AGE_RANGE']].groupby(['AGE_RANGE']).count()\n",
        "AGE_RANGE1\n"
      ],
      "metadata": {
        "id": "XKSKjUCLJQY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax2 = plt.subplots(nrows = 1, figsize=(15,8))\n",
        "AGE_RANGE1.plot(ax = ax2, kind = 'bar')\n",
        "ax2.title.set_text('Colisiones con fatalidad por intervalo de edad del conductor')"
      ],
      "metadata": {
        "id": "siKo8QXXJiXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agrupamos la variable P_SEX_1 que contiene un 1 si es mujer (F) y un 0 si  es hombre, y sumamos cuantos datos C_SEV hay en cada valor de variable por la que agrupamos\n"
      ],
      "metadata": {
        "id": "6Cyz5SC1JiGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_SEX_1_1= X_Datos_train_acc1[['C_SEV','P_SEX_1']].groupby(['P_SEX_1']).count()\n",
        "P_SEX_1_1\n"
      ],
      "metadata": {
        "id": "LEiozeQ-JlKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax2 = plt.subplots(nrows = 1, figsize=(15,8))\n",
        "P_SEX_1_1.plot(ax = ax2, kind = 'bar')\n",
        "ax2.title.set_text('Colisiones con fatalidad por genero del conductor')"
      ],
      "metadata": {
        "id": "Zu8f3_qlJk9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agrupamos la variable P_USER y sumamos cuantos datos C_SEV hay en cada valor de variable por la que agrupamos"
      ],
      "metadata": {
        "id": "9bHiOhCTJtI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_USER1=X_Datos_train_acc1[['C_SEV','P_USER']].groupby(['P_USER']).count()\n",
        "P_USER1\n"
      ],
      "metadata": {
        "id": "N8O6LP4_JvTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax2 = plt.subplots(nrows = 1, figsize=(15,8))\n",
        "P_USER1.plot(ax = ax2, kind = 'bar')\n",
        "ax2.title.set_text('Colisiones con fatalidad por tipo de usuario')"
      ],
      "metadata": {
        "id": "KXlu47X6JyKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Agrupamos la variable P_SAFE y sumamos cuantos datos C_SEV hay en cada valor de variable por la que agrupamos"
      ],
      "metadata": {
        "id": "6k_uvMPgJ0LZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "P_SAFE1=X_Datos_train_acc1[['C_SEV','P_SAFE']].groupby(['P_SAFE']).count()\n",
        "P_SAFE1\n"
      ],
      "metadata": {
        "id": "DegO7TJ3J3Ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax2 = plt.subplots(nrows = 1, figsize=(15,8))\n",
        "P_SAFE1.plot(ax = ax2, kind = 'bar')\n",
        "ax2.title.set_text('Colisiones con fatalidad por tipo de seguridad')"
      ],
      "metadata": {
        "id": "OzAVmGw8J3o9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agrupamos la variable P_ISEV y sumamos cuantos datos C_SEV hay en cada valor de variable por la que agrupamos"
      ],
      "metadata": {
        "id": "IVoq6cDgJ7mI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_ISEV1=X_Datos_train_acc1[['C_SEV',\"P_ISEV\"]].groupby([\"P_ISEV\"]).count()\n",
        "P_ISEV1\n"
      ],
      "metadata": {
        "id": "9eK5hRqlJ9cS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax2 = plt.subplots(nrows = 1, figsize=(15,8))\n",
        "P_ISEV1.plot(ax = ax2, kind = 'bar')\n",
        "ax2.title.set_text('Colisiones con fatalidad por grado de severidad')"
      ],
      "metadata": {
        "id": "PcfuH6-KKA_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusiones"
      ],
      "metadata": {
        "id": "yXR8C6WBKEPn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Entre las características de los vehículos que tienden a tener más accidente priman\n",
        "\n",
        "-\tLos vehículos tipo 1 que corresponden a los vehículos de tipo ligero (vehículo de pasajeros, furgonetas...)\n",
        "-\tLa mayoría de las colisiones con fatalidad son de los vehículos cuyo modelo es del 1979- 2015, especialmente lo del año 2001\n",
        "\n",
        "\n",
        "Por otro lado, entre las características de los conductores que tienden a tener más accidentes priman:\n",
        "\n",
        "-\tLos conductores entre las de edades de 20 y 60 años, con un repunte de los conductores cuyas edades oscilan entre los 20 y 30 años\n",
        "-\tDestacan más los accidentes con fatalidad cuyos conductores son hombres\n",
        "-\tEntre los tipos de usuarios que conducen en el momento del accidente, se encuentran los conductores de coches, los ciclistas y los motoristas\n",
        "-\tLa mayoría llevan un elemento de seguridad, como el cinturón, en el comento de la colisión \n",
        "-\tSobre la severidad de la colisión destaca que gran parte mueren en el acto (3- fatalidad)"
      ],
      "metadata": {
        "id": "GyfQpdJ2KC7g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ¿Qué tipos de vehículos (modelos, antigüedad, etc.) y conductores son menos propensos a tener accidentes (descuento en prima)?"
      ],
      "metadata": {
        "id": "T73sbxMkKIx6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para analizar cuales son las caracteristicas de los vehiculos y las caracteristicas de los conductores que tienen una memor propension a tener accidentes, hemos considerado que vamos utilizar el metodo utilizado previamente con la funcion groupby()\n",
        "Como hemos mencionando anteriormente, la variable C_SEV contiene dos valores:\n",
        "\n",
        "    1-> cuando la colision ha producido al menos una fatalidad\n",
        "    2-> cuando la colision no ha producido ninguna fatalidad\n",
        "\n",
        "Como no hay ninguna columna que contenga los datos sobre el descuenta en prima, hemos interpretado que para establecer dicho descuento va a depender de si no hay ninguna fatalidad, cuya informacion la contiene el valor \"2\" de la variable C_SEV y como es lo que queremos estudiar en ete apartado, procedemos a selecionar a continuacion unicamente los valores \"2\" de esta columna. \n",
        "\n",
        "Para ello, vamos a utilizar el dataset train que se encuentra en la variable X_Datos_train_acc que ya tiene las columnas con la informacion necesaria para determinar las caracteristicas, la filtracion por los datos del conductor unicamente, el index reseteado, la columna Year_range y la columna AGE_RANGE creadas.\n",
        "\n",
        "La nueva variable que contiene unicamente los valores \"2\" de la columna C_SEV es X_Datos_train_acc2"
      ],
      "metadata": {
        "id": "hmY__tNyKLd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_Datos_train_acc2= X_Datos_train_acc[X_Datos_train_acc[\"C_SEV\"].isin([2])]\n",
        "X_Datos_train_acc2= X_Datos_train_acc[X_Datos_train_acc[\"C_SEV\"].isin([2])]"
      ],
      "metadata": {
        "id": "8rQ8iLCkKKxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agrupamos la variable V_TYPE y sumamos cuantos datos C_SEV hay en cada valor de variable por la que agrupamos"
      ],
      "metadata": {
        "id": "S3FkEjM2KQlO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "V_TYPE2= X_Datos_train_acc2[['C_SEV','V_TYPE']].groupby([\"V_TYPE\"]).count()\n",
        "V_TYPE2\n"
      ],
      "metadata": {
        "id": "nfZHEWtPKTcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax2 = plt.subplots(nrows = 1, figsize=(15,8))\n",
        "V_TYPE2.plot(ax = ax2, kind = 'bar')\n",
        "ax2.title.set_text('Colisiones sin fatalidad por tipo de vehiculo')"
      ],
      "metadata": {
        "id": "KhVC1rvdKUaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como comentabamos previamente. Para el analisis del año de produccion de cada vehiculo, primero agrupamos la variable V_YEAR y sumamos cuantos datos C_SEV hay en cada valor de la variable por la que agrupamos\n"
      ],
      "metadata": {
        "id": "mukUKTyXKW2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "V_YEAR2= X_Datos_train_acc2[['C_SEV','V_YEAR']].groupby(['V_YEAR']).count()\n",
        "V_YEAR2\n"
      ],
      "metadata": {
        "id": "tRy-cvKgKYto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax2 = plt.subplots(nrows = 1, figsize=(20,10))\n",
        "V_YEAR2.plot(ax = ax2, kind = 'bar')\n",
        "ax2.title.set_text('Colisiones sin fatalidad por año del modelo del vehiculo')"
      ],
      "metadata": {
        "id": "jGBwe9qSKZTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En segundo lugar, para obtener unos resultados mas generales agrupamos la variable Year_range y sumamos cuantos datos C_SEV hay en cada valor por el que agrupamos\n"
      ],
      "metadata": {
        "id": "zxG87UipKbj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Year_range2= X_Datos_train_acc[['C_SEV','Year_range']].groupby(['Year_range']).count()\n",
        "Year_range2\n"
      ],
      "metadata": {
        "id": "jzKyoQTeKbEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax2 = plt.subplots(nrows = 1, figsize=(15,8))\n",
        "Year_range2.plot(ax = ax2, kind = 'bar')\n",
        "ax2.title.set_text('Colisiones sin fatalidad por rango de año del modelo del vehiculo')"
      ],
      "metadata": {
        "id": "yhpq3qQ5KgCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_AGE2= X_Datos_train_acc2[['C_SEV','P_AGE']].groupby(['P_AGE']).count()\n",
        "P_AGE2\n"
      ],
      "metadata": {
        "id": "4aBxdsmcKqn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax2 = plt.subplots(nrows = 1, figsize=(20,10))\n",
        "P_AGE2.plot(ax = ax2, kind = 'bar')\n",
        "ax2.title.set_text('Colisiones sin fatalidad por rango de edad del conductor')"
      ],
      "metadata": {
        "id": "OwWsDA9VKsYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zBAqmHzHKj0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "AGE_RANGE2=X_Datos_train_acc2[['C_SEV','AGE_RANGE']].groupby(['AGE_RANGE']).count()\n",
        "AGE_RANGE2\n",
        "fig, ax2 = plt.subplots(nrows = 1, figsize=(15,8))\n"
      ],
      "metadata": {
        "id": "IeMB2DbxKxDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AGE_RANGE2.plot(ax = ax2, kind = 'bar')\n",
        "ax2.title.set_text('Colisiones con fatalidad por intervalo de edad del conductor')"
      ],
      "metadata": {
        "id": "PSu203xnKypJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agrupamos la variable P_SEX_1 que contiene un 1 si es mujer (F) y un 0 si es hombre, y sumamos cuantos datos C_SEV hay en cada valor de variable por la que agrupamos\n"
      ],
      "metadata": {
        "id": "Yg1Q9twQK0t5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "P_SEX_1_2= X_Datos_train_acc2[['C_SEV','P_SEX_1']].groupby(['P_SEX_1']).count()\n",
        "P_SEX_1_2\n"
      ],
      "metadata": {
        "id": "pBiE-1YjK2qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax2 = plt.subplots(nrows = 1, figsize=(15,8))\n",
        "P_SEX_1_2.plot(ax = ax2, kind = 'bar')\n",
        "ax2.title.set_text('Colisiones sin fatalidad por genero del conductor')"
      ],
      "metadata": {
        "id": "qRe2vFFZK37V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agrupamos la variable P_USER y sumamos cuantos datos C_SEV hay en cada valor de variable por la que agrupamos"
      ],
      "metadata": {
        "id": "ZUHpKgTKK8Wa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "P_USER2=X_Datos_train_acc2[['C_SEV','P_USER']].groupby(['P_USER']).count()\n",
        "P_USER2\n"
      ],
      "metadata": {
        "id": "EXytPceXK8DR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax2 = plt.subplots(nrows = 1, figsize=(15,8))\n",
        "P_USER2.plot(ax = ax2, kind = 'bar')\n",
        "ax2.title.set_text('Colisiones sin fatalidad por tipo de usuario ')"
      ],
      "metadata": {
        "id": "NuIbWBoeLA1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agrupamos la variable P_ISEV y sumamos cuantos datos C_SEV hay en cada valor de variable por la que agrupamos\n"
      ],
      "metadata": {
        "id": "ZyiBlad5LEtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_SAFE2=X_Datos_train_acc2[['C_SEV','P_SAFE']].groupby(['P_SAFE']).count()\n",
        "fig, ax2 = plt.subplots(nrows = 1, figsize=(15,8))\n",
        "P_SAFE2.plot(ax = ax2, kind = 'bar')\n",
        "ax2.title.set_text('Colisiones sin fatalidad por la seguridad del conductor')"
      ],
      "metadata": {
        "id": "ayWIftAYLFVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agrupamos la variable P_ISEV y sumamos cuantos datos C_SEV hay en cada valor de variable por la que agrupamos\n"
      ],
      "metadata": {
        "id": "7TXpAuuTLHM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P_ISEV2=X_Datos_train_acc1[['C_SEV',\"P_ISEV\"]].groupby([\"P_ISEV\"]).count()\n",
        "P_ISEV2"
      ],
      "metadata": {
        "id": "487haEWZLKWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax2 = plt.subplots(nrows = 1, figsize=(15,8))\n",
        "P_ISEV2.plot(ax = ax2, kind = 'bar')\n",
        "ax2.title.set_text('Colisiones sin fatalidad por severidad del conductor')"
      ],
      "metadata": {
        "id": "bpyPmLknLLye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusiones"
      ],
      "metadata": {
        "id": "OX9tQ0uPLNR-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entre las características de los vehículos que tienden a tener menos accidente priman:\n",
        "\n",
        "-\tLos vehículos tipo 1 que corresponden a los vehículos de tipo ligero (vehículo de pasajeros, furgonetas...)\n",
        "-\tLa mayoría de las colisiones con fatalidad son de los vehículos cuyo modelo es del 1979- 2015, especialmente los del año 2000\n",
        "\n",
        "\n",
        "Por otro lado, entre las características de los conductores que tienden a tener menos accidentes priman:\n",
        "\n",
        "-\tLos conductores entre las de edades de 20 y 60 años, con un repunte de los conductores cuyas edades oscilan entre los 20 y 30 años\n",
        "-\tDestacan más los accidentes con fatalidad cuyos conductores son hombres\n",
        "-\tEntre los tipos de usuarios que conducen en el momento del accidente, se encuentran los conductores de coches, los ciclistas y los motoristas\n",
        "-\tLa mayoría llevan un elemento de seguridad, como el cinturón, en el comento de la colisión \n",
        "-\tSobre la severidad de la colisión destaca que gran parte mueren en el acto (3- fatalidad)"
      ],
      "metadata": {
        "id": "TmybOhLtLNKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ¿Qué es lo que mas contribuye a que existan fallecimientos en un accidente?"
      ],
      "metadata": {
        "id": "n0ztF3cPerAY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para este apartado, voy a tomar la variable C_SEV como objetivo, siendo 1 si hay fallecimientos en el accidente, y 2 si no ha habido fallecimientos. "
      ],
      "metadata": {
        "id": "XQk1A4swhlBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "porcentaje_f = Datos[\"C_SEV\"].value_counts(normalize=True).mul(100).rename('percent').reset_index()\n",
        "count_f = Datos[\"C_SEV\"].value_counts().reset_index()\n",
        "Union_f= pd.merge(porcentaje_f, count_f, on=['index'], how='inner')\n",
        "fig = px.histogram(Union_f, x=\"index\", y=['percent'], labels={'index':'fatality'})\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "slezcM5ejwpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos ver como de desbalanceado está el dataset, solo un 1.7% de los accidentes suponen al menos un fallecimiento."
      ],
      "metadata": {
        "id": "KM9ogBTzozdV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estacionalidad"
      ],
      "metadata": {
        "id": "zHTLhGhMKdNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Datos_temporal = pd.DataFrame()\n",
        "Datos_temporal[\"date\"] = pd.DatetimeIndex(Datos[\"C_YEAR\"].map(str) + \"-\" + Datos[\"C_MNTH\"].map(str))\n",
        "Datos_temporal[\"fatal\"] = np.where(Datos[\"C_SEV\"]==1, 1, 0)\n",
        "Datos_temporal[\"non_fatal\"] = np.where(Datos[\"C_SEV\"]==2, 1, 0)"
      ],
      "metadata": {
        "id": "vJtDrdSqKeb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tiempo_colisión = Datos_temporal.groupby('date')[\"fatal\",\"non_fatal\"].sum()\n",
        "plot = tiempo_colisión.plot(figsize = (15,5), title = \"Deadly colissions over time\")\n",
        "plot.set_xlabel(\"Year\")\n",
        "plot.set_ylabel(\"Number of deadly colissions\")"
      ],
      "metadata": {
        "id": "zg86uM1YMHRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Puedo observar que existe un ciclo en los accidentes no fatales, hay momentos del año en los que el numero de accidentes no fatales es mayor."
      ],
      "metadata": {
        "id": "XvwkxAKKQRg5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora hago la misma grafica para ver solo los accidentes fatales, ya que en esta gráfica no puedo sacar ninguna conclusion acerca de los accidentes fatales al estar tan desbalanceados los datos"
      ],
      "metadata": {
        "id": "rQmPlsBAQFOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tiempo_colision_fatal = Datos_temporal.groupby('date')[\"fatal\"].sum()\n",
        "plot = tiempo_colision_fatal.plot(figsize = (15,5), title = \"Deadly colissions over time\")\n",
        "plot.set_xlabel(\"Year\")\n",
        "plot.set_ylabel(\"Number of deadly colissions\")"
      ],
      "metadata": {
        "id": "gsEm2Qa5Qn3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voy a reducir el rango temporal para sacar conclusiones más especificas acerca de que época del año contribuye a que haya mas accidentes con fallecimientos. Partiendo de 2010"
      ],
      "metadata": {
        "id": "0g8FryctQq2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_reduced = Datos_temporal.loc[Datos_temporal[\"date\"] >= \"2010\"]\n",
        "tiempo_colision_fatal = df_reduced.groupby('date')[\"fatal\"].sum()\n",
        "\n",
        "\n",
        "plot = tiempo_colision_fatal.plot(figsize = (15,5), title = \"Deadly colissions over time\")\n",
        "plot.set_xlabel(\"Year\")\n",
        "plot.set_ylabel(\"Number of deadly colissions\")"
      ],
      "metadata": {
        "id": "FUylX9a1Q9MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tiempo_colision_no_fatal = df_reduced.groupby('date')[\"non_fatal\"].sum()\n",
        "\n",
        "plot = tiempo_colision_no_fatal.plot(figsize = (15,5), title = \"Deadly colissions over time\", color=\"orange\")\n",
        "plot.set_xlabel(\"Year\")\n",
        "plot.set_ylabel(\"Number of deadly colissions\")"
      ],
      "metadata": {
        "id": "vfxH06miRAfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Efectivamente existe una relacion temporal, a mediados de año es cuando mas accidentes "
      ],
      "metadata": {
        "id": "DVsjzYC9MqH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlación de mi variable objetivo C_SEV"
      ],
      "metadata": {
        "id": "ec20gWeaMtE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.plotting import autocorrelation_plot\n",
        "plt.figure(figsize=(15,5))\n",
        "for c in tiempo_colisión.columns:\n",
        "    autocorrelation_plot(tiempo_colisión[c][-60:],label=c);"
      ],
      "metadata": {
        "id": "AI9iAIASM4VQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La variable C_SEV se comporta igual para ambos valores"
      ],
      "metadata": {
        "id": "OU1SmMpeVrgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "sns.regplot('fatal', 'non_fatal', data=tiempo_colisión);"
      ],
      "metadata": {
        "id": "2F-pjZ_7M7At"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ademas, aqui podemos ver que existe una relación lineal entre la fatalidad y la no fatalidad, propia del algoritmo regresión lineal "
      ],
      "metadata": {
        "id": "_cGWR6myV1e6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr = tiempo_colisión.corr()\n",
        "print(\"La correlación entre los accidentes fatales y no fatales es de\", str(round(corr[\"fatal\"][\"non_fatal\"], 3)))\n",
        "corr"
      ],
      "metadata": {
        "id": "NV93oApIM-I0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "He decidido afrontar este apartado analizando aquellos factores que considero mas determinantes a la hora de que existan fallecimientos en un accidente, en vez de volver a implementar los algoritmos de clasificación y regresión."
      ],
      "metadata": {
        "id": "DoSZ8AtSO89D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análisis de la carretera."
      ],
      "metadata": {
        "id": "2vHGE-qzPiFB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo primero, defino las funciones que voy a aplicar en mis representaciones graficas; una función que mide la mortalidad de los accidentes(que sería una muestra más reducida ya que toma solo los fallecimientos), otra la mortalidad total (que irá siempre de la mano de la frecuencia ya que es un porcentaje y por tanto está influenciada por el desbalanceamiento de los datos), y por ultimo la frecuencia. Y también un boxplot"
      ],
      "metadata": {
        "id": "eY0obg5PWAdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Función mortalidad (% / 100 Accidentes)\n",
        "def mortalidad(columna, tipos, titulo, data):\n",
        "    analysis = data.groupby([columna, \"C_SEV\"]).size()\n",
        "    serie = list()\n",
        "    for i in range(0, np.int8(len(analysis) / 2)):\n",
        "        serie.append(analysis[:, 1].iloc[[i]].item() / (\n",
        "                    analysis[:, 1].iloc[[i]].item() + (analysis[:, 2].iloc[[i]].item())) * 100)\n",
        "    analysis = pd.Series(serie, index=range(0, np.int8(len(analysis) / 2)))\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    plot = analysis.plot(kind=\"bar\", title=titulo, color=\"#3A5683\")\n",
        "    plot.set_xticklabels(tipos, rotation=45)"
      ],
      "metadata": {
        "id": "fu1xwSoIeibe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Función mortalidad total\n",
        "def mortalidadtotal(columna, tipos, titulo, data):\n",
        "    analysis = data.groupby(columna)[\"C_SEV\"].sum() / data[\"C_SEV\"].sum() * 100\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    plot = analysis.plot(kind=\"bar\", title=titulo, color=\"#76B041\")\n",
        "    plot.set_xticklabels(tipos, rotation=45)"
      ],
      "metadata": {
        "id": "go1sQiFnO6z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Función frecuencia absoluta\n",
        "def frecuencia(columna, tipos, titulo, data):\n",
        "    analysis = data.groupby(columna)[\"C_SEV\"].count()\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    plot = analysis.plot(kind=\"bar\", title=titulo, color=\"#639A88\")\n",
        "    plot.set_xticklabels(tipos, rotation=45)"
      ],
      "metadata": {
        "id": "7DNeVnp1dJ_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def boxplot_fatality(var, data):\n",
        "    f, ax = plt.subplots(figsize=(14, 6))\n",
        "    sns.boxplot(x=var, y='C_SEV', data=data, orient='h')"
      ],
      "metadata": {
        "id": "sJjhIuKSYuJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tipos = ['Mid-block','At an intersection','Intersection with parking lot entrance/exit',\n",
        "            'Railroad crossing','Bridge','Tunnel','Passing or climbing lane',\n",
        "             'Ramp','Traffic circle','Highway express lane', 'Other']\n",
        "\n",
        "frecuencia(\"C_RCFG\", tipos, \"Collisions by road configuration\", Datos)\n",
        "mortalidadtotal(\"C_RCFG\", tipos, \"Percentage of deadly collisions by road configuration\", Datos)\n",
        "mortalidad(\"C_RCFG\", tipos, \"Mortality rate on accidents by road configuration\", Datos)"
      ],
      "metadata": {
        "id": "fwYQk9ZQPkAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos concluir que hay un mayor indice de accidentes en el sentido de la marcha y en las intersecciones, aunque en relació´n con la mortalidad, lo que mas contribuye son los carriles VAO y los de adelantamiento. "
      ],
      "metadata": {
        "id": "ocWhdEXzFDC4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estado del asfalto"
      ],
      "metadata": {
        "id": "k3-o8tdpjaGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tipos = ['Dry, normal','Wet','Snow','Slush ,wet snow','Icy','Sand/gravel/dirt','Muddy','Oil','Flooded', 'Other']\n",
        "frecuencia(\"C_RSUR\", tipos, \"Collisions by surface\",Datos)\n",
        "mortalidadtotal(\"C_RSUR\", tipos, \"Percentage of deadly collisions by surface\",Datos)\n",
        "mortalidad(\"C_RSUR\", tipos, \"Mortality rate on accidents by surface\",Datos)"
      ],
      "metadata": {
        "id": "lLmUCx64jiII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el caso del estado del asfalto, por temas de probabilidad, hay mas accidentes en condiciones normales, pero los accidentes mortales son caracterisitcos cuando el estado de la carretera es pésimo, con charcos, con grava..."
      ],
      "metadata": {
        "id": "mnkKOpLlWOc_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Condiciones climaticas"
      ],
      "metadata": {
        "id": "jvrG-3VifDrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tipos = ['Clear','Cloudy','Rain','Snow','Freezing Rain,Hail',\n",
        "                'Low Visibility','Strong Wind','Other']\n",
        "frecuencia(\"C_WTHR\", tipos, \"Collisions by weather\",Datos)\n",
        "mortalidadtotal(\"C_WTHR\", tipos, \"Percentage of deadly collisions by weather\",Datos)\n",
        "mortalidad(\"C_WTHR\", tipos, \"Mortality rate on accidents by weather\",Datos)"
      ],
      "metadata": {
        "id": "iU65PzAGfJIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como las graficas anteriores, hay mas accidentes en condiciones climaticas normales, sin embargo, la tasa de mortalidad es mas alta cuando hay baja visibilidad, fuertes vientos o granizo"
      ],
      "metadata": {
        "id": "qRjrkXwYWPb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Según tipo de vehiculo"
      ],
      "metadata": {
        "id": "fbzanne9kBMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tipos = v_type = ['Light Duty', 'Cargo <4.5t', 'Truck <4.5t',\n",
        "          'Truck >4.5t', 'Road tractor', 'School bus',\n",
        "          'Small school bus', 'Urban bus', 'Motorcycle',\n",
        "          'Off-road', 'Bicycle', 'Motorhome', 'Farm equip.',\n",
        "          'Constru. equip.', 'Fire engine', 'Snowmobile',\n",
        "          'Street car', 'Not vehicle', 'Others']\n",
        "             \n",
        "frecuencia(\"V_TYPE\", tipos, \"Collisions by vehicle type\",Datos)\n",
        "mortalidadtotal(\"V_TYPE\", tipos, \"Percentage of deadly collisions by vehicle type\",Datos)\n",
        "mortalidad(\"V_TYPE\", tipos, \"Mortality rate on accidents by vehicle type\",Datos)"
      ],
      "metadata": {
        "id": "XLK1FxstkEa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui es mas de lo mismo, nos encontramos con que hay más accidentes con coches estandar, ya que por la cantidad es lo más probable. Aqui es interesante la tasa de mortalidad ya uqe se distribuye mas por los distintos valores. Se pueden sacar conclusiones respecto a que tipo de trabajo se realizan con cada tipo de vehiculo. Aunque hay que tener en cuenta que es posible que la muestra en este caso no sea representativa.\n",
        "\n"
      ],
      "metadata": {
        "id": "5cNqm1X6WQKa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora vamos a analizar que caracteristicas de los conductores contribuyen mas a que haya fallecimientos. En primer lugar, analicemos el sexo del conductor"
      ],
      "metadata": {
        "id": "qNNdwlpXJRAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tipos = [\"Female\", \"Male\"]\n",
        "frecuencia(\"P_SEX\", tipos, \"Collisions by sex\", Datos)\n",
        "mortalidadtotal(\"P_SEX\", tipos, \"Percentage of deadly collisions by sex\", Datos)\n",
        "mortalidad(\"P_SEX\", tipos, \"Mortality rate on accidents by sex\", Datos)"
      ],
      "metadata": {
        "id": "VG8-nVx3JrM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos ver una distribución balanceada. Puede ser porque hay más hombres en el mundo y además hay más hombres con carnet de conducir que mujeres. Además, en los trabajos de conducción suelen haber mas hombres que mujeres. Mueren más hombres que mujeres en los accidentes, puede ser por lo que acabo de mencionar y porque los hombres son más temerarios que las mujeres. Aqui podemos demostrar la falsedad del prejuicio de que las mujeres conducen peor."
      ],
      "metadata": {
        "id": "JFO--GD8WT6p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Según la edad del conductor"
      ],
      "metadata": {
        "id": "v5vJ2Q_LKxlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tipos = sorted(np.int8(Datos['P_AGE'].dropna().unique()))\n",
        "boxplot_fatality(\"P_AGE\",Datos)\n",
        "frecuencia(\"P_AGE\", tipos, \"Collisions by passenger age\",Datos)\n",
        "mortalidadtotal(\"P_AGE\", tipos, \"Percentage of deadly collisions by passenger age\",Datos)\n",
        "mortalidad(\"P_AGE\", tipos, \"Mortality rate on accidents by passenger age\",Datos)"
      ],
      "metadata": {
        "id": "oUBSQDuHJk8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquellos conductores cuya edad oscila entre los 16 y 28 años, son mas propensos a tener accidentes. Sin embargo mueren los conductores de avanzada edad, con alguna pequeña excepción causada por la baja representatividad de la muestra.\n"
      ],
      "metadata": {
        "id": "l8xAH0GXWUjC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Según seguridad del conductor"
      ],
      "metadata": {
        "id": "Ssp7OtrQLcaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tipos = ['No safety device used','Safety device used','Helmet',\n",
        "          'Reflective clothing',\n",
        "          'Other safety device','No safety device equipped', 'Not applicable', 'Other']\n",
        "\n",
        "\n",
        "frecuencia(\"P_SAFE\", tipos, \"Collisions by safety device used by passengers\", Datos)\n",
        "mortalidadtotal(\"P_SAFE\", tipos, \"Percentage of deadly collisions by safety device used by passengers\", Datos)\n",
        "mortalidad(\"P_SAFE\", tipos, \"Mortality rate on accidents by safety device used by passengers\", Datos)"
      ],
      "metadata": {
        "id": "gik2XWAzLfLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este analisis es muy util para verificar la utilidad de los equipos de seguridad. En este caso, hay una baja representatividad debido a la muestra. Hay mas accidentes cuando se usa un equipo de seguridad, debido a que aumenta la muestra."
      ],
      "metadata": {
        "id": "sIy-_hcVWVG6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Según si es motociclista, conductor, pasajero..."
      ],
      "metadata": {
        "id": "wCQgZlmvLtFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tipos = [\"Motor Vehicle Driver\", \"Motor Vehicle Passenger\", \"Pedestrian\", \"Bicyclist\", \"Motorcyclist\"]\n",
        "frecuencia(\"P_USER\", tipos, \"Collisions by passenger role\",Datos)\n",
        "mortalidadtotal(\"P_USER\", tipos, \"Percentage of deadly collisions by passenger role\",Datos)\n",
        "mortalidad(\"P_USER\", tipos, \"Mortality rate on accidents by passenger role\",Datos)"
      ],
      "metadata": {
        "id": "k2CXW4qtLyN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como era de esperar, mueren mas biciclistas ya que están mas expuestos al peligro. Y en el caso de la frecuencia de accidentes, vuelve a influir el peso de la muestra."
      ],
      "metadata": {
        "id": "GDEcBkuXSenQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6K2LCBQi0izV"
      },
      "source": [
        " # Dado un accidente, ¿se puede generar un modelo que prediga si habrá fallecimientos o no? ¿Si se va a necesitar tratamiento médico o no? Las aseguradoras tienen que inmovilizar capital para pagar estas casuísticas"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Este aparta y el siguiente no lo hemos podido comentar correctamente debido a que algunas lineas de codigo tardaban mas de una hora en ejecutarse**"
      ],
      "metadata": {
        "id": "5qaok3Jw1gUQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlBNpf_HO1Ss"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_boston\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.inspection import permutation_importance\n",
        "import multiprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBd14QtPM--h"
      },
      "outputs": [],
      "source": [
        "Datos_test_dummy= Datos_test_dummy.drop(['P_ISEV','V_ID','P_ID', 'C_SEV'], axis= 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xy4N2S6Z1P6H"
      },
      "outputs": [],
      "source": [
        "Datos_test_dummy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwkYcpLcTiAZ"
      },
      "source": [
        "Eliminamos estas 3 variables ya que P_ISEV da la misma informacion que C_SEV, y tanto V_ID y P_ID son el número de identidad de las personas involucradas que no nos dan ninguna info relevante"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1RQAYkV2sRl"
      },
      "outputs": [],
      "source": [
        "Datos_train_dummy= Datos_train_dummy.drop(['P_ISEV','V_ID','P_ID'], axis= 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iK0zogn3Nrzf"
      },
      "outputs": [],
      "source": [
        "Datos_train_dummy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6r-9c2mNXAF"
      },
      "outputs": [],
      "source": [
        "cat_cols = Datos_train_dummy.select_dtypes(include=['object', 'category']).columns.to_list()\n",
        "numeric_cols = Datos_train_dummy.select_dtypes(include=['float64', 'int']).columns.to_list()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CReamos dos variables en las cuales ontenemos las variables numericas por un lado y por otro las variables no numericas (tanto \"objecto\" como \"float\"). De esta forma podremos trabajar mas adelante con ellas de manera mas comoda y diferencial\n"
      ],
      "metadata": {
        "id": "1q_hRB5GcMzH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "We5bIGFcOUM5"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "                    [('onehot', OneHotEncoder(handle_unknown='ignore'), cat_cols)],\n",
        "                    remainder='passthrough'\n",
        "               )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aprovechando las variables con solo las categoricas, realizamos un OHE para convertir en codigo binario las variables. Que dejen de ser categoricas. Esto nos hara mas facil trabajar con el dataset y es importante a la hora de realizar predicciones con arboles. "
      ],
      "metadata": {
        "id": "b2V1DV-FchsS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTfHmmAYOg9p"
      },
      "outputs": [],
      "source": [
        "X_train_prep = preprocessor.fit_transform(Datos_train_dummy)\n",
        "X_test_prep  = preprocessor.transform(Datos_test_dummy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cI4n0EPCSvvs"
      },
      "outputs": [],
      "source": [
        "X_train_prep = pd.DataFrame(X_train_prep)\n",
        "X_test_prep  = pd.DataFrame(X_test_prep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQhmsekQYtzg"
      },
      "outputs": [],
      "source": [
        "X_train_prep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riH2Pc0bS4Ry"
      },
      "source": [
        "## GRID SEARCH BASADO EN OUT-BAG SCORE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpqnuC9rS9d_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "144c907e-0678-42ac-eff2-7c0b45830c39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo: {'criterion': 'gini', 'max_depth': 5, 'max_features': 10, 'n_estimators': 100} ✓\n"
          ]
        }
      ],
      "source": [
        "param_grid = ParameterGrid(\n",
        "                {'n_estimators': [100],\n",
        "                 'max_features': [10, 15, 19],\n",
        "                 'max_depth'   : [5, 10, 15],\n",
        "                 'criterion'   : ['gini', 'entropy']\n",
        "                }\n",
        "            )\n",
        "\n",
        "# Loop para ajustar un modelo con cada combinación de hiperparámetros\n",
        "# ==============================================================================\n",
        "resultados = {'params': [], 'oob_accuracy': []}\n",
        "\n",
        "for params in param_grid:\n",
        "    \n",
        "    modelo = RandomForestClassifier(\n",
        "                oob_score    = True,\n",
        "                n_jobs       = -1,\n",
        "                random_state = 123,\n",
        "                ** params\n",
        "             )\n",
        "    modelo.fit(X_train_prep, y_Datos_train)\n",
        "    \n",
        "    resultados['params'].append(params)\n",
        "    resultados['oob_accuracy'].append(modelo.oob_score_)\n",
        "    print(f\"Modelo: {params} \\u2713\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con el grid search buscamos optimizar los hiperparametros, es decir, aquellos factores que definiran nuestros arboles. Estos factors son muy importantes y de ellos dependera la precision y eficiencia de los resultados finales. Por ejemplo, no es bueno que en un random forest los arboles o estvimadors que forman parte del metodo esten relacionados entre si. Si cogemos muchas variables para cada arbol es cada vez mas sencillo que haya arboles que cometan los mismos errores.Tampoco es bueno coger excesivamente pocas variables. Para cosas como esta nos sirve el GRID SEARCH. Para saber el nivel optimo de cada hiperparametro."
      ],
      "metadata": {
        "id": "zEGOdFp1fUnt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRkyRKqLzOw-"
      },
      "outputs": [],
      "source": [
        " resultados = pd.DataFrame(resultados)\n",
        "resultados = pd.concat([resultados, resultados['params'].apply(pd.Series)], axis=1)\n",
        "resultados = resultados.drop(columns = 'params')\n",
        "resultados = resultados.sort_values('oob_r2', ascending=False)\n",
        "resultados.head(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Libertad para generar análisis de valor y nuevas ideas. Se debe atacar mínimo un modelo (estimar si habrá fallecidos o no). Hecho esto, se puede plantear de forma opcional otros alcances (libertad para plantear opciones)."
      ],
      "metadata": {
        "id": "vpZW8sOG3seb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Esteapartado no lo hemos podido comentar correctamente porque algunas lineas de codigo tardaban mas de una hora en ejecutarse**"
      ],
      "metadata": {
        "id": "ixjveJ1z1tTa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKQHQNE78x3z"
      },
      "source": [
        "## ARBOL DE DECISIÓN SIMPLE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4GKUChOUrvo"
      },
      "outputs": [],
      "source": [
        "Datos_test_dummy= Datos_test_dummy.drop(['C_SEV'], axis= 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2DlMG3A-9tW"
      },
      "outputs": [],
      "source": [
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "# Create Decision Tree classifer object\n",
        "clf_tree = DecisionTreeClassifier()\n",
        "# Train Decision Tree Classifer\n",
        "clf_tree = clf_tree.fit(Datos_train_dummy, y_Datos_train)\n",
        "#Predict the response for test dataset\n",
        "y_pred_tree=clf_tree.predict(Datos_test_dummy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los resultados de la matriz de confusion según el modelo de regresión logistica muestra que siendo la prediccion correcta habría 9826 colisiones sin fatalidades y en caso de que la predicción realizada no fuese correcta habria 823236 de colisiones sin fatalidad.\n",
        "\n",
        "Por otro lado tanto si es correcta la predicción habría 4568\n",
        "colisiones con al menos una fatalidad y si no es correcta habría 13860  colisiones con al menos una fatalidad.\n"
      ],
      "metadata": {
        "id": "5i6W0I-Kv6ci"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WokMnuH7EDnR"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix = confusion_matrix(y_Datos_test, y_pred_tree)\n",
        "print(confusion_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Para valorar los resultados de la matrix anterior he utilizado distintas metricas\n",
        "•\tPrecision: medimos la calidad. En este caso el 0,25% de las colisiones tendrían al menos una fatalidad y el modelo se equivocaría un 99,75 % de las veces cuando prediga que la colisión tiene al menos una fatalidad \n",
        "•\tRecall: informa sobre la cantidad que el modelo es capaz de identificar. En este caso el modelo es capaz de identificar el 32% de las colisiones con al menos una fatalidad y al 98% de las colisiones con ninguna fatalidad\n",
        "•\tF1-Score:se utiliza para combinar las medidas de precisión y recall en un sólo valor.\n",
        "•\tAccuracy: mide el porcentaje de casos que el modelo ha acertado. Los resultados muestran que el modelo acierta un 97% de las veces\n"
      ],
      "metadata": {
        "id": "X9PBhc4xv20c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQUP4XzdEO8n"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_Datos_test,y_pred_tree))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_BWrqVXFb_c"
      },
      "source": [
        "## BAGGING CLASSIFIER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkMcv4BUVS-9"
      },
      "outputs": [],
      "source": [
        "escalar = StandardScaler()\n",
        "Datos_train_dummy = escalar.fit_transform(Datos_train_dummy )\n",
        "Datos_test_dummy = escalar.transform(Datos_test_dummy )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgU3erXDFfIT"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score\n",
        "from sklearn.model_selection import StratifiedKFold,cross_validate\n",
        "\n",
        "h = BaggingClassifier()\n",
        "h.fit(Datos_train_dummy,y_Datos_train)\n",
        "y_pred_bag= h.predict(Datos_test_dummy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg6US9n2H-6K"
      },
      "source": [
        "MATRIZ DE CONFUSIÓN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcYrCG83H5Cu"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix = confusion_matrix(y_Datos_test, y_pred_bag)\n",
        "print(confusion_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrPSPUCdIH4y"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_Datos_test,y_pred_bag))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GRADIENT BOOSTING"
      ],
      "metadata": {
        "id": "oWwF4dn3SJhI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgzDI-L5WgBM"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "modelo_gb = GradientBoostingClassifier(\n",
        "              learning_rate=0.1,  max_depth=12,\n",
        "              min_weight_fraction_leaf=0.02, n_estimators=130,\n",
        "              random_state=2408,\n",
        "              verbose=1)\n",
        "modelo_gb.fit(Datos_test_dummy, y_Datos_test)\n",
        "predicciones = modelo_gb.predict(Datos_test_dummy)\n",
        "\n",
        "# Error de test del modelo inicial\n",
        "rmse = mean_squared_error(\n",
        "        y_true  = y_Datos_test,\n",
        "        y_pred  = predicciones,\n",
        "        squared = False\n",
        "       )\n",
        "print(f\"El error (rmse) de test es: {rmse}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAfjeb4zXsve"
      },
      "outputs": [],
      "source": [
        "modelo_gb.score(Datos_train_dummy, y_Datos_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONFUSION MATRIX"
      ],
      "metadata": {
        "id": "6mTkzZQ8SQvX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-w9WX61mX-WZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix = confusion_matrix(y_Datos_test, predicciones)\n",
        "print(confusion_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jL0T6Qz8YIVs"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_Datos_test, predicciones))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZHQWLaOYT-4"
      },
      "outputs": [],
      "source": [
        "classifiers = [GradientBoostingClassifier()]# estudiar los hiperparametros y usar cualquier modelo aprendid\n",
        "\n",
        "for classifier in classifiers:\n",
        "  pipe = Pipeline(steps=[('classifier', classifier)])\n",
        "  pipe.fit(Datos_train_dummy, Datos_test_dummy)   \n",
        "  print(classifier)\n",
        "  print(\"model score: %.3f\" % pipe.score(Datos_train_dummy, Datos_test_dummy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeyuRhesYsN8"
      },
      "source": [
        "IMPORTANCIA VARIABLES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9-nWhB3YuhM"
      },
      "outputs": [],
      "source": [
        "feature_importance = modelo_gb.feature_importances_\n",
        "# make importances relative to max importance\n",
        "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
        "sorted_idx = np.argsort(feature_importance)\n",
        "pos = np.arange(sorted_idx.shape[0]) + .5\n",
        "# plt.subplot(1, 2, 2)\n",
        "plt.figure(figsize=(12, 20))\n",
        "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
        "plt.yticks(pos, Datos_train_dummy.keys()[sorted_idx])\n",
        "plt.xlabel('Relative Importance')\n",
        "plt.title('Variable Importance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## REGRESION LOGISTICA"
      ],
      "metadata": {
        "id": "y_37GbL2D2hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "modelo_rl = LogisticRegression()\n",
        "modelo_rl.fit(X_train_1s, y_train)\n",
        "y_pred_lr=modelo_rl.predict(X_test_1)"
      ],
      "metadata": {
        "id": "T9Pj9ZQrS5zX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONFUSION MATRIX"
      ],
      "metadata": {
        "id": "PIhZ4LIVTN-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix = confusion_matrix(y_test, y_pred_lr)\n",
        "print(confusion_matrix)"
      ],
      "metadata": {
        "id": "uHfZl7sYS7wR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred_lr))"
      ],
      "metadata": {
        "id": "LOZ5z9tUTCFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "logit_roc_auc = roc_auc_score(y_test, modelo_rl.predict(X_test_1))\n",
        "fpr, tpr, thresholds = roc_curve(y_test, modelo_rl.predict_proba(X_test_1)[:,1])\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig('Log_ROC')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zeusdQjhTEMi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "JdH70-qvor6W",
        "jBh5GLgKozsh",
        "VedzTo2mo70W",
        "BdvTtyOlUNG0",
        "NXFm3b4-Hah9"
      ],
      "name": "Practica_Final.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}